{
  "hash": "3d67946b97e481587ebbd14c813e6f98",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"End to End Machine Learning CI/CD Pipeline\"\nsubtitle: \"From ideation to production\"\nauthor: \"Mulimbika Makina\"\ndate: 2025-08-03\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    number-sections: true\n    code-fold: true         # ← Makes all code blocks collapsible\n    code-summary: \"View Code\"  # ← Label for collapsed blocks\n    df-print: paged\ntheme: cosmo\ncategories: [Machine Learning, MLOps, Model Deployment, Data Pipelines, FastAPI, Docker]\n\n---\n\n# Overview\n\n- The initial phase in deploying a machine learning model involves translating a business concept into a well-defined machine learning problem statement.\n- The subsequent phase entails formulating the architectural design to outline the structure and components of the end-to-end pipeline.\n\nThis article explores each stage of the machine learning lifecycle, from ideation to deployment, supported by hands-on examples and best practices.\n\n# 1. Problem Definition\n\nWe begin with a hypothetical business scenario:  \n> *A telecom company wants to reduce customer churn by predicting whether a customer is likely to leave in the next billing cycle.*\n\n## 1.1 Business Goals\n- Reduce churn by 15%\n- Improve targeting of retention campaigns\n\n## 1.2 ML Problem Statement\nTransform this into a binary classification task.\n\n## 1.3 KPIs\n- Accuracy, Precision, Recall, F1-Score\n- Customer Retention Rate\n\n---\n\n# 2. Architecture Design\n\nThe pipeline consists of the following stages:\n1. Data ingestion & validation\n2. Preprocessing\n3. Model training & tuning\n4. Deployment\n5. Monitoring & feedback\n\n![Figure 1: Architecture of a production-ready end-to-end ML pipeline.](pipeline.svg){ width=500 }\n\n\nWe use tools like `pandas`, `scikit-learn`, `FastAPI`, `Docker`, and `MLflow`.\n\n---\n\n# 3. Data Pipeline\n\n## 3.1 Data Ingestion\n- Load data from CSV, database, or cloud storage\n- Use version control (e.g., `DVC`)\n\n## 3.2 Data Validation\n\n::: {#73f282d4 .cell execution_count=1}\n``` {.python .cell-code}\n# import pandas as pd\n```\n:::\n\n\n## 3.3 Preprocessing\n\n::: {#2e59edc1 .cell execution_count=2}\n``` {.python .cell-code}\n# from sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler()\n# X_scaled = scaler.fit_transform(df[['tenure', 'monthly_charges']])\n```\n:::\n\n\n# 4. Model Development\n## 4.1 Exploratory Data Analysis (EDA)\n\n- Correlation heatmap\n\n- Distribution plots\n\n## 4.2 Model Selection\n\n- Baseline: Logistic Regression\n\n- Advanced: Random Forest, XGBoost\n\n## 4.3 Hyperparameter Tuning\n\n::: {#039f6b3b .cell execution_count=3}\n``` {.python .cell-code}\n# from optuna import create_study\n# Define and optimize objective...\n```\n:::\n\n\n# 5. Model Evaluation\n\n- Evaluate on unseen test set\n\n- Use classification report and confusion matrix\n\n## 5.1 Model Explainability\n\n- Use SHAP to explain model predictions.\n\n# 6. Model Deployment\n## 6.1 Package with Docker\n\n```{dockerfile}\n# FROM python:3.12\n# COPY . /app\n# WORKDIR /app\n# RUN pip install -r requirements.txt\n# CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n## 6.2 Serve with FastAPI\n\n::: {#b92569c5 .cell execution_count=4}\n``` {.python .cell-code}\n# from fastapi import FastAPI\n# app = FastAPI()\n\n# @app.post(\"/predict\")\n# def predict(data: dict):\n    # Load model and return prediction\n```\n:::\n\n\n# 7. Monitoring & Logging\n## 7.1 Log with MLflow\n- Track experiments\n\n- Log metrics, parameters, and artifacts\n\n## 7.2 Monitor Drift\n- Use evidently to monitor data and performance drift.\n\n# 8. Feedback Loop & Retraining\n## 8.1 Collect Feedback\n- Store user interactions or prediction correctness.\n\n## 8.2 Trigger Retraining\n- Schedule weekly retraining with Airflow.\n\n# Conclusion & Takeaways\n- ML deployment requires much more than just training a good model.\n\n- Tools like FastAPI, Docker, MLflow, and CI/CD pipelines are essential.\n\n- Feedback loops and monitoring are key to real-world success.\n\n# References\n\n- [scikit-learn](https://scikit-learn.org/)\n- [MLflow](https://mlflow.org/)\n- [FastAPI](https://fastapi.tiangolo.com/)\n- [Docker](https://www.docker.com/)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}